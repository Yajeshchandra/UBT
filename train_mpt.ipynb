{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f578c7e",
   "metadata": {},
   "source": [
    "# Biometric Fusion with MPT Training\n",
    "\n",
    "This notebook implements the training process for the Multi-Modal Biometric Fusion model with Modified Prompt Tuning (MPT).\n",
    "\n",
    "## Overview\n",
    "\n",
    "The model combines:\n",
    "1. CNN feature extractors for periocular, forehead, and iris images\n",
    "2. Transformer-based fusion with modified prompt tuning\n",
    "3. Multiple loss functions for optimal embedding learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "\n",
    "from model.model_mpt import BiometricModel\n",
    "from model.dataset import BiometricDataset\n",
    "from model.loss import InfoNCELoss, ContrastiveLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e71741",
   "metadata": {},
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "Set up the hyperparameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc854b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Training parameters\n",
    "params = {\n",
    "    'data_path': './dataset2',            # Path to dataset\n",
    "    'embedding_dim': 512,                 # Dimension of embeddings\n",
    "    'batch_size': 32,                     # Batch size for training\n",
    "    'epochs': 100,                         # Number of training epochs\n",
    "    'learning_rate': 3e-4,                # Learning rate\n",
    "    'weight_decay': 1e-5,                 # Weight decay for optimizer\n",
    "    'save_dir': './checkpoints',          # Directory to save checkpoints\n",
    "    'save_interval': 5,                   # Save model every N epochs\n",
    "    'k1': 0.5,                            # Weight for ContrastiveLoss\n",
    "    'k2': 0.5,                            # Weight for InfoNCELoss\n",
    "    'temperature': 0.05,                  # Temperature for InfoNCE loss\n",
    "    'margin': 2.0                         # Margin for Contrastive loss\n",
    "}\n",
    "\n",
    "# Create save directory if it doesn't exist\n",
    "os.makedirs(params['save_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214988b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Load and prepare datasets for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c59675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomRotation(degrees=3),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
    "    transforms.RandomPosterize(bits=6, p=0.1),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=1.5, p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = BiometricDataset(root_dir=params['data_path'], transform=transform_train, \n",
    "                                instances_per_person=8, split='train')\n",
    "test_dataset = BiometricDataset(root_dir=params['data_path'], transform=transform_val, \n",
    "                               instances_per_person=8, split='test')\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6a36f",
   "metadata": {},
   "source": [
    "## Model Definition and Loss Functions\n",
    "\n",
    "Create the model and define loss functions for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a503b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = BiometricModel(embedding_dim=params['embedding_dim']).to(device)\n",
    "\n",
    "# Initialize loss functions\n",
    "infonce_criterion = InfoNCELoss(temperature=params['temperature'])\n",
    "contrastive_criterion = ContrastiveLoss(margin=params['margin'])\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=params['learning_rate'], \n",
    "                              weight_decay=params['weight_decay'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe68ff",
   "metadata": {},
   "source": [
    "## Training and Validation Functions\n",
    "\n",
    "Define functions for training and validation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8338ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, infonce_criterion, contrastive_criterion, \n",
    "               periocular, forehead, iris, labels, device, k1=0.5, k2=0.5):\n",
    "    \"\"\"Perform one training step\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    periocular = periocular.to(device)\n",
    "    forehead = forehead.to(device)\n",
    "    iris = iris.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    embeddings = model(periocular, forehead, iris)\n",
    "    \n",
    "    # Calculate both losses and combine them with weights\n",
    "    infonce_loss = infonce_criterion(embeddings, labels)\n",
    "    contrastive_loss = contrastive_criterion(embeddings, labels)\n",
    "    loss = k1 * contrastive_loss + k2 * infonce_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), infonce_loss.item(), contrastive_loss.item()\n",
    "\n",
    "def validate(model, val_loader, infonce_criterion, contrastive_criterion, device, k1=0.5, k2=0.5):\n",
    "    \"\"\"Perform validation on the validation set\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_infonce_loss = 0.0\n",
    "    val_contrastive_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            perioculars = batch['perioculars'].view(-1, 1, 128, 128).to(device)\n",
    "            foreheads = batch['foreheads'].view(-1, 1, 128, 128).to(device)\n",
    "            irises = batch['irises'].view(-1, 1, 128, 128).to(device)\n",
    "            labels = batch['labels'].view(-1).to(device)\n",
    "            \n",
    "            embeddings = model(perioculars, foreheads, irises)\n",
    "            \n",
    "            # Calculate both losses\n",
    "            infonce_loss = infonce_criterion(embeddings, labels)\n",
    "            contrastive_loss = contrastive_criterion(embeddings, labels)\n",
    "            loss = k1 * contrastive_loss + k2 * infonce_loss\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_infonce_loss += infonce_loss.item()\n",
    "            val_contrastive_loss += contrastive_loss.item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_infonce_loss = val_infonce_loss / len(val_loader)\n",
    "    avg_val_contrastive_loss = val_contrastive_loss / len(val_loader)\n",
    "    \n",
    "    return avg_val_loss, avg_val_infonce_loss, avg_val_contrastive_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860f668",
   "metadata": {},
   "source": [
    "## Embedding Visualization Function\n",
    "\n",
    "Function to visualize the learned embeddings using t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings(model, dataset, device, num_persons=10, num_samples=10, epoch=0):\n",
    "    \"\"\"Visualize embeddings using t-SNE\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    # Select first n persons\n",
    "    person_ids = dataset.person_ids[:num_persons]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for person_id in person_ids:\n",
    "            for i in range(num_samples):\n",
    "                label = dataset.label_map[person_id]\n",
    "                # Randomly select one iris, periocular, and forehead image\n",
    "                iris_img_path = np.random.choice(dataset.iris_images[person_id])\n",
    "                periocular_img_path = np.random.choice(dataset.periocular_images[person_id])\n",
    "                forehead_img_path = np.random.choice(dataset.forehead_images[person_id])\n",
    "                \n",
    "                # Load and transform images\n",
    "                transform = dataset.transform\n",
    "                iris_img = transform(Image.open(iris_img_path).convert('L')).unsqueeze(0).to(device)\n",
    "                periocular_img = transform(Image.open(periocular_img_path).convert('L')).unsqueeze(0).to(device)\n",
    "                forehead_img = transform(Image.open(forehead_img_path).convert('L')).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Get embedding\n",
    "                emb = model(periocular_img, forehead_img, iris_img).cpu().numpy()\n",
    "                embeddings.append(emb[0])\n",
    "                labels.append(label)\n",
    "    \n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings)-1))\n",
    "    embeddings_2d = tsne.fit_transform(np.array(embeddings))\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_persons):\n",
    "        idx = [j for j, l in enumerate(labels) if l == i]\n",
    "        plt.scatter(embeddings_2d[idx, 0], embeddings_2d[idx, 1], label=f'Person {person_ids[i]}', s=10)\n",
    "    \n",
    "    plt.title(f'Embedding Visualization (Epoch {epoch+1})')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{params[\"save_dir\"]}/embeddings_epoch_{epoch+1}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a2cc0",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Execute the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracking variables\n",
    "epochs = []\n",
    "losses = []\n",
    "infonce_losses = []\n",
    "contrastive_losses = []\n",
    "val_losses = []\n",
    "val_infonce_losses = []\n",
    "val_contrastive_losses = []\n",
    "\n",
    "# Track best validation loss for model saving\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = params['epochs']\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # Training phase\n",
    "    total_loss = 0\n",
    "    total_infonce_loss = 0\n",
    "    total_contrastive_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # Reshape batch\n",
    "        perioculars = batch['perioculars'].view(-1, 1, 128, 128)\n",
    "        foreheads = batch['foreheads'].view(-1, 1, 128, 128)\n",
    "        irises = batch['irises'].view(-1, 1, 128, 128)\n",
    "        labels = batch['labels'].view(-1)\n",
    "        \n",
    "        # Train step\n",
    "        loss, infonce_loss, contrastive_loss = train_step(\n",
    "            model, optimizer, infonce_criterion, contrastive_criterion, \n",
    "            perioculars, foreheads, irises, labels, device, \n",
    "            k1=params['k1'], k2=params['k2']\n",
    "        )\n",
    "        \n",
    "        total_loss += loss\n",
    "        total_infonce_loss += infonce_loss\n",
    "        total_contrastive_loss += contrastive_loss\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_infonce_loss = total_infonce_loss / len(train_loader)\n",
    "    avg_contrastive_loss = total_contrastive_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_infonce_loss, val_contrastive_loss = validate(\n",
    "        model, val_loader, infonce_criterion, contrastive_criterion, \n",
    "        device, k1=params['k1'], k2=params['k2']\n",
    "    )\n",
    "    \n",
    "    # Update learning rate based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Track metrics\n",
    "    epochs.append(epoch + 1)\n",
    "    losses.append(avg_loss)\n",
    "    infonce_losses.append(avg_infonce_loss)\n",
    "    contrastive_losses.append(avg_contrastive_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_infonce_losses.append(val_infonce_loss)\n",
    "    val_contrastive_losses.append(val_contrastive_loss)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  InfoNCE Loss: {avg_infonce_loss:.4f}, Val InfoNCE Loss: {val_infonce_loss:.4f}\")\n",
    "    print(f\"  Contrastive Loss: {avg_contrastive_loss:.4f}, Val Contrastive Loss: {val_contrastive_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f\"{params['save_dir']}/model_latest_mpt.pt\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f\"{params['save_dir']}/model_latest_mpt_best.pt\")\n",
    "        print(f\"  Model saved with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Save checkpoint at intervals\n",
    "    if (epoch + 1) % params['save_interval'] == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': avg_loss,\n",
    "            'val_loss': val_loss\n",
    "        }, f\"{params['save_dir']}/checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Visualize embeddings periodically\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        visualize_embeddings(model, test_dataset, device, num_persons=20, epoch=epoch)\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, losses, label='Total Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Total Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Total Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, infonce_losses, label='InfoNCE Training')\n",
    "    plt.plot(epochs, val_infonce_losses, label='InfoNCE Validation')\n",
    "    plt.plot(epochs, contrastive_losses, label='Contrastive Training')\n",
    "    plt.plot(epochs, val_contrastive_losses, label='Contrastive Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Component Losses')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{params['save_dir']}/learning_curves.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print time estimates\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    avg_epoch_time = (time.time() - start_time) / (epoch + 1)\n",
    "    remaining_time = avg_epoch_time * (num_epochs - (epoch + 1))\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time:.2f}s. Estimated time left: {remaining_time/60:.2f} minutes.\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c85fbd",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "\n",
    "Evaluate the trained model and visualize final embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for final evaluation\n",
    "model.load_state_dict(torch.load(f\"{params['save_dir']}/model_latest_mpt_best.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# Final validation\n",
    "final_val_loss, final_val_infonce, final_val_contrastive = validate(\n",
    "    model, val_loader, infonce_criterion, contrastive_criterion, \n",
    "    device, k1=params['k1'], k2=params['k2']\n",
    ")\n",
    "\n",
    "print(f\"Final validation loss: {final_val_loss:.4f}\")\n",
    "print(f\"Final validation InfoNCE loss: {final_val_infonce:.4f}\")\n",
    "print(f\"Final validation Contrastive loss: {final_val_contrastive:.4f}\")\n",
    "\n",
    "# Generate final t-SNE visualization with more persons\n",
    "visualize_embeddings(model, test_dataset, device, num_persons=30, num_samples=10, epoch=num_epochs)\n",
    "\n",
    "print(\"Training and evaluation completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
